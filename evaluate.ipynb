{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_embeddings = np.load(\"sbert_umap_25d.npy\")\n",
    "tfidf_embeddings = np.load(\"tfidf_umap50d.npy\")\n",
    "\n",
    "sbert_clusters = np.load(\"sbert_clusters.npy\")\n",
    "tfidf_clusters = np.load(\"tfidf_clusters.npy\")\n",
    "\n",
    "true_labels = np.load(\"true_labels.npy\")\n",
    "sbert_clusters_kmeans = np.load(\"sbert_clusters_kmeans.npy\")\n",
    "\n",
    "sloberta_embeddings = np.load(\"sloberta_umap_25d.npy\")\n",
    "sloberta_clusters = np.load(\"sloberta_clusters_dbscan.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29493, 25)\n",
      "(29493,)\n"
     ]
    }
   ],
   "source": [
    "print(sbert_embeddings.shape)\n",
    "print(sbert_clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 29493 preprocessed articles.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_combined_jsonl(filename=\"preprocessed_combined.jsonl\"):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line.strip()) for line in f if line.strip()]\n",
    "\n",
    "# Example usage\n",
    "preprocessed_texts = load_combined_jsonl()\n",
    "print(f\"‚úÖ Loaded {len(preprocessed_texts)} preprocessed articles.\")\n",
    "tokenized_texts = [text.split() for text in preprocessed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skupina', 'brics', 'nov', 'polnopraven', 'ƒçlanica', 'egipt', 'etiopija', 'iran', 'savdski', 'arabija', 'zdru≈æen', 'arabski', 'emirat', 'polnopraven', 'ƒçlan', 'skupina', 'velik', 'gospodarstvo', 'vzpon', 'brics', 'ƒçlanica', 'voditelj', 'dozdaj≈°nji', 'ƒçlanica', 'brics', 'brazilija', 'rusija', 'indija', 'kitajska', 'ju≈æen', 'afrika', 'sprejetje', 'nov', 'ƒçlanica', 'vrh', 'skupina', 'avgust', 'johannesburg', 'skupina', 'peterica', 'skupina', 'argentina', 'dan', 'nov', 'argentinski', 'predsednik', 'javier', 'milea', 'pismo', 'voditelj', 'brics', 'stali≈°ƒçe', 'nov', 'vlada', '≈°tevilen', 'pogled', 'predhoden', 'oblast', 'pravi', 'ƒças', 'pridru≈æitev', 'skupina', 'argentina', 'ƒçlanica', 'skupina', 'omre≈æje', 'november', 'nov', 'argentinski', 'zunanji', 'ministrica', 'diana', 'mondino', 'milea', 'predvolilen', 'kampanja', 'simpatija', 'zda', 'izrael', 'prekinitev', 'stik', 'brazilija', 'kitajska', 'zanimanje', 'pridru≈æitev', 'skupina', 'navedba', 'ju≈ænoafri≈°ki', 'zunanji', 'ministrica', 'naledi', 'pandor', 'dr≈æava', 'nov', 'ƒçlanica', '≈æelja', 'ƒçlanstvo', 'drug', 'al≈æirija', 'banglade≈°', 'venezuel', 'tajska', 'skupina', 'brics', 'nov', 'ƒçlanica', 'brazilij', 'rusija', 'indija', 'kitajska', 'ju≈æen', 'afrika', 'dr≈æava', 'geopolitiƒçen', 'gospodarski', 'polo≈æaj', 'svet', 'ƒçlanica', 'skupina', 'sprejetje', 'nov', 'odstotek', 'svetoven', 'prebivalstvo', 'odstotek', 'ozemlje', 'odstotek', 'bruto', 'domaƒç', 'proizvod', 'vojna', 'ukrajina', 'nevtralen', 'dr≈æa', 'okvir', 'leto', 'ustanovljen', 'skupina', 'protiute≈æ', 'gospodarski', 'prevlada', 'zahod']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Embedding': 'SLOBERTA-DBSCAN', 'Silhouette': 0.31070593, 'Davies-Bouldin': 1.026054296956046, 'ARI': 0.29383417882004975, 'NMI': 0.5639818237269971, 'Num Clusters': 28, 'Noise Points': 0, 'Embedding Alignment': 0.9986762, 'Avg NPMI': 0.09113513693637}\n",
      "{'Embedding': 'SBERT', 'Silhouette': 0.31920457, 'Davies-Bouldin': 1.0093945344303572, 'ARI': 0.2322979492079684, 'NMI': 0.49488931728741375, 'Num Clusters': 26, 'Noise Points': 0, 'Embedding Alignment': 0.9991281, 'Avg NPMI': 0.08708324263406085}\n",
      "{'Embedding': 'TFIDF', 'Silhouette': 0.32474416, 'Davies-Bouldin': 1.0185792309972688, 'ARI': 0.17818023641450698, 'NMI': 0.42428634930358, 'Num Clusters': 27, 'Noise Points': 0, 'Embedding Alignment': 0.9994208, 'Avg NPMI': 0.09520921248178979}\n",
      "{'Embedding': 'SBERT-KMEANS', 'Silhouette': 0.3659727, 'Davies-Bouldin': 0.9945940220041651, 'ARI': 0.2323831969718441, 'NMI': 0.49544835436713974, 'Num Clusters': 26, 'Noise Points': 0, 'Embedding Alignment': 0.9991866, 'Avg NPMI': 0.09023254501353344}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def embedding_alignment_score(embeddings, labels):\n",
    "    label_set = set(labels)\n",
    "    if -1 in label_set:\n",
    "        label_set.remove(-1)\n",
    "\n",
    "    similarities = []\n",
    "    for label in label_set:\n",
    "        cluster_embeddings = embeddings[labels == label]\n",
    "        if len(cluster_embeddings) < 2:\n",
    "            continue\n",
    "        sim_matrix = cosine_similarity(cluster_embeddings)\n",
    "        upper_triangle = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "        similarities.append(np.mean(upper_triangle))\n",
    "\n",
    "    return np.mean(similarities) if similarities else None\n",
    "\n",
    "\n",
    "def evaluate_all(embeddings, clusters, label_name, tokenized_texts=None, true_labels=None):\n",
    "    mask = clusters != -1\n",
    "    # NPMI Coherence (based on tokenized_texts)\n",
    "    if tokenized_texts is not None:\n",
    "        dictionary = Dictionary(tokenized_texts)\n",
    "        cluster_topics = []\n",
    "        for cluster_id in np.unique(clusters):\n",
    "            if cluster_id == -1:\n",
    "                continue  # Skip noise\n",
    "            docs = [tokenized_texts[i] for i in range(len(clusters)) if clusters[i] == cluster_id]\n",
    "            if not docs:\n",
    "                continue\n",
    "            cluster_dictionary = Dictionary(docs)\n",
    "            corpus = [cluster_dictionary.doc2bow(doc) for doc in docs]\n",
    "            # Get top words for topic (just the dictionary keys sorted by frequency)\n",
    "            word_freq = {}\n",
    "            for doc in corpus:\n",
    "                for word_id, freq in doc:\n",
    "                    word_freq[word_id] = word_freq.get(word_id, 0) + freq\n",
    "            sorted_words = sorted(word_freq.items(), key=lambda x: -x[1])\n",
    "            topic_words = [cluster_dictionary[word_id] for word_id, _ in sorted_words[:10]]\n",
    "            cluster_topics.append(topic_words)\n",
    "\n",
    "        cm = CoherenceModel(\n",
    "            topics=cluster_topics,\n",
    "            texts=tokenized_texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence='c_npmi'\n",
    "        )\n",
    "        avg_npmi = cm.get_coherence()\n",
    "    else:\n",
    "        avg_npmi = None\n",
    "    metrics = {\n",
    "        \"Embedding\": label_name,\n",
    "        \"Silhouette\": silhouette_score(embeddings[mask], clusters[mask]) if np.sum(mask) > 1 else None,\n",
    "        \"Davies-Bouldin\": davies_bouldin_score(embeddings[mask], clusters[mask]) if np.sum(mask) > 1 else None,\n",
    "        \"ARI\": adjusted_rand_score(true_labels, clusters) if true_labels is not None else None,\n",
    "        \"NMI\": normalized_mutual_info_score(true_labels, clusters) if true_labels is not None else None,\n",
    "        \"Num Clusters\": len(set(clusters)) - (1 if -1 in clusters else 0),\n",
    "        \"Noise Points\": np.sum(clusters == -1),\n",
    "        \"Embedding Alignment\": embedding_alignment_score(embeddings, clusters),\n",
    "        \"Avg NPMI\": avg_npmi\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Evaluate both embeddings\n",
    "print(evaluate_all(\n",
    "    embeddings=sloberta_embeddings,\n",
    "    clusters=sloberta_clusters,\n",
    "    label_name=\"SLOBERTA-DBSCAN\",\n",
    "    tokenized_texts=tokenized_texts,  # list of token lists for each doc\n",
    "    true_labels=true_labels  # optional\n",
    "))\n",
    "print(evaluate_all(\n",
    "    embeddings=sbert_embeddings,\n",
    "    clusters=sbert_clusters,\n",
    "    label_name=\"SBERT\",\n",
    "    tokenized_texts=tokenized_texts,  # list of token lists for each doc\n",
    "    true_labels=true_labels  # optional\n",
    "))\n",
    "print(evaluate_all(\n",
    "    embeddings=tfidf_embeddings,\n",
    "    clusters=tfidf_clusters,\n",
    "    label_name=\"TFIDF\",\n",
    "    tokenized_texts=tokenized_texts,  # list of token lists for each doc\n",
    "    true_labels=true_labels  # optional\n",
    "))\n",
    "print(evaluate_all(\n",
    "    embeddings=sbert_embeddings,\n",
    "    clusters=sbert_clusters_kmeans,\n",
    "    label_name=\"SBERT-KMEANS\",\n",
    "    tokenized_texts=tokenized_texts,  # list of token lists for each doc\n",
    "    true_labels=true_labels  # optional\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding: \"Do points within the same cluster have higher embedding similarity than across clusters?\"\n",
    "bad on tfidf ... sparse, high dimensional\n",
    "\n",
    "\n",
    "Silhouette Score: Separation and cohesion of clusters.\n",
    "Davies-Bouldin Index: Lower is better.\n",
    "ARI / NMI: Ground truth comparison (if labels are available).\n",
    "Embedding Alignment: Average cosine similarity within clusters.\n",
    "Avg NPMI: Semantic coherence of extracted words per cluster (requires tokenized texts).\n",
    "\n",
    "üü© Summary:\n",
    "Embedding Alignment is nearly perfect for both (which is expected)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
